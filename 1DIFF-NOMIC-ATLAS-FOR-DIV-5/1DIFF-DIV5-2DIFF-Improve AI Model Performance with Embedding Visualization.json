{
  "title": "Improve AI Model Performance with Embedding Visualization",
  "overview": {
    "description": "This guide explains how to use Nomic Atlas's interactive embedding visualizations to improve AI model accuracy by debugging models, detecting overlapping clusters, and refining vector search performance.",
    "purpose": "To provide engineers with tools to visualize embedding decision boundaries and optimize model performance.",
    "key_points": [
      "Quickly diagnose model failures.",
      "Optimize embedding separability for better performance.",
      "Debug vector search, clustering, and classification models."
    ]
  },
  "why_visualization_matters": {
    "description": "Embeddings encode data into high-dimensional spaces for AI applications like NLP, recommendation systems, and search engines. Poorly formed embeddings lead to misclassification and poor performance.",
    "issues_detected": [
      "Cluster overlap causing poor classification performance.",
      "Misclassified points requiring dataset adjustments.",
      "Feature drift in embeddings over different training iterations."
    ]
  },
  "setup": {
    "requirements": [
      "Install required libraries using: `pip install nomic numpy torch torchvision pytorch-lightning`.",
      "Login to Nomic using your API key: `nomic login`."
    ]
  },
  "steps_to_visualize_embeddings": {
    "step_1": {
      "title": "Create Your Embeddings Data Map",
      "details": [
        "Train a neural network to generate embeddings.",
        "Upload the generated embeddings to Nomic Atlas."
      ]
    },
    "step_2": {
      "title": "Train a Simple Neural Network",
      "details": [
        "Use a Multi-Layer Perceptron (MLP) to classify MNIST digits.",
        "Create embeddings from the model's final layer outputs."
      ],
      "code_snippet": {
        "language": "python",
        "content": "import os\nimport torch\nfrom pytorch_lightning import LightningModule, Trainer\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, datasets\n\nclass MNISTModel(LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(28 * 28, 10)\n        self.l2 = torch.nn.Linear(10, 10)\n\n    def forward(self, x):\n        return torch.relu(self.l2(torch.relu(self.l1(x.view(x.size(0), -1)))))\n\n    def training_step(self, batch, batch_nb):\n        x, y = batch\n        logits = self(x)\n        loss = F.cross_entropy(logits, y)\n        return loss\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=0.02)\n\ntrain_ds = datasets.MNIST(os.environ.get(\"PATH_DATASETS\", \".\"), train=True, download=True, transform=transforms.ToTensor())\ntrain_loader = DataLoader(train_ds, batch_size=256)\n\nmnist_model = MNISTModel()\ntrainer = Trainer(accelerator=\"auto\", max_epochs=15)\ntrainer.fit(mnist_model, train_dataloaders=train_loader)"
      }
    },
    "step_3": {
      "title": "Generate Embeddings and Metadata",
      "details": [
        "Extract embeddings from the model's final layer.",
        "Prepare metadata for each data point, including labels, predictions, and image links."
      ],
      "code_snippet": {
        "language": "python",
        "content": "all_embeddings = []\nall_data = []\nfor batch_idx, batch in enumerate(test_loader):\n    x, y = batch\n    logits = mnist_model(x)\n    embeddings = logits.detach().numpy()\n    predictions = torch.argmax(logits, dim=1).detach().numpy()\n    image_links = [f'https://s3.amazonaws.com/static.nomic.ai/mnist/eval/{label}/{batch_idx * BATCH_SIZE + idx}.jpg' for idx, label in enumerate(y)]\n    batch_data = [{\n        'label': str(int(label)),\n        'prediction': str(int(prediction)),\n        'image': image,\n        'id': f'{batch_idx * BATCH_SIZE + idx}'\n    } for idx, (label, image, prediction) in enumerate(zip(y.tolist(), image_links, predictions))]\n    all_embeddings.append(embeddings)\n    all_data.extend(batch_data)"
      }
    },
    "step_4": {
      "title": "Upload to Nomic Atlas",
      "details": [
        "Create an AtlasDataset and add embeddings and metadata.",
        "Generate a data map using the `create_index()` method."
      ],
      "code_snippet": {
        "language": "python",
        "content": "from nomic import AtlasDataset\nimport numpy as np\n\ndataset = AtlasDataset('mnist-model-embeddings', description='Embeddings of an MNIST model')\ndataset.add_data(embeddings=np.concatenate(all_embeddings), data=all_data)\ndata_map = dataset.create_index()"
      }
    },
    "step_5": {
      "title": "Visualize Embeddings in Atlas",
      "details": [
        "Explore the embedding space in Atlas to identify clusters, overlaps, and decision boundaries.",
        "Focus on overlapping clusters to detect misclassifications or ambiguous data points."
      ]
    }
  },
  "key_indicators_of_embedding_quality": {
    "good": "Tight, well-separated clusters suggest strong feature learning.",
    "warning": "Overlapping clusters indicate classification uncertainty.",
    "bad": "Sparse, unstructured embeddings may signal poor feature extraction."
  },
  "conclusion": {
    "summary": "Embedding visualizations provide deeper insights into AI model performance, helping engineers debug and optimize classification, clustering, and vector search tasks.",
    "tools": "Nomic Atlas simplifies embedding visualization through interactive tools for analyzing high-dimensional data."
  }
}